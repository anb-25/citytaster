# =====================================================================
# FILE: .github/workflows/citytaster-deploy.yml
# PURPOSE: CI builds/pushes images to ECR, syncs S3 data, then updates EC2 via SSH.
# RELATION TO APP: ships your frontend/backend images and restarts the compose stack on the host.
# =====================================================================
name: CityTaster Deploy

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1          # keep aligned with infra/aws/envs/dev
  DB_NAME: CityTasterDB          # used in your mongoimport loop
  ENV_DIR: infra/aws/envs/dev    # where Terraform env lives (optional use below)

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # --- Checkout ---------------------------------------------------
      - name: Checkout code
        uses: actions/checkout@v4

      # --- (Recommended) Use OIDC to assume an AWS role (no long-lived keys)
      # To enable: create an IAM role with a trust policy for GitHub OIDC and grant ECR/S3/EC2.
      # Then set: role-to-assume + aws-region below and REMOVE aws-access-key-id/secret.
      # - name: Configure AWS credentials (OIDC)
      #   uses: aws-actions/configure-aws-credentials@v4
      #   with:
      #     role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
      #     aws-region: ${{ env.AWS_REGION }}

      # --- (Current) Access keys path (works today; rotate regularly) --
      - name: Configure AWS credentials (access keys)
        if: ${{ !env.AWS_ROLE_TO_ASSUME }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # --- Optional: read Terraform outputs if you configured a remote backend (S3/DynamoDB) ---
      # PURPOSE: avoid hardcoding ECR/S3/EC2 info in Secrets.
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
      - name: Read Terraform outputs (if backend configured)
        id: tf
        shell: bash
        run: |
          set -euo pipefail
          # If you later add a remote backend, uncomment backend-configs and add secrets:
          # terraform -chdir="$ENV_DIR" init \
          #   -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
          #   -backend-config="key=${{ secrets.TF_STATE_KEY }}" \
          #   -backend-config="region=${{ env.AWS_REGION }}" \
          #   -backend-config="dynamodb_table=${{ secrets.TF_LOCK_TABLE }}"
          terraform -chdir="$ENV_DIR" init -input=false >/dev/null 2>&1 || true
          terraform -chdir="$ENV_DIR" output -json >/tmp/outs.json || echo '{}' >/tmp/outs.json
          jq -r 'to_entries[] | "\(.key)=\(.value.value)"' /tmp/outs.json | tee -a "$GITHUB_ENV" || true
          # Exposes: ecr_backend_url, ecr_frontend_url, s3_bucket_name, aws_account_id, ec2_public_ip (if applied)

      # --- Ensure repos exist, login to ECR --------------------------------
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      # Derive ECR repo URLs if TF outputs aren't available yet
      - name: Derive ECR URLs (fallback)
        if: ${{ !env.ecr_backend_url || !env.ecr_frontend_url }}
        run: |
          echo "ecr_backend_url=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/citytaster-backend" >> $GITHUB_ENV
          echo "ecr_frontend_url=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/citytaster-frontend" >> $GITHUB_ENV

      # --- Buildx for multi-arch -------------------------------------------
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # --- Build & push backend --------------------------------------------
      - name: Build and push backend Docker image
        run: |
          docker buildx build \
            --push \
            -f deployment/Dockerfile.backend \
            -t "${{ env.ecr_backend_url }}:latest" \
            .

      # --- Build & push frontend -------------------------------------------
      - name: Build and push frontend Docker image
        run: |
          docker buildx build \
            --push \
            -f deployment/Dockerfile.frontend \
            -t "${{ env.ecr_frontend_url }}:latest" \
            .

      # --- Ensure EC2 is running (cost saver) ------------------------------
      - name: Start EC2 instance
        run: aws ec2 start-instances --instance-ids ${{ secrets.EC2_INSTANCE_ID }} --region $AWS_REGION
      - name: Wait for EC2 to be running
        run: aws ec2 wait instance-running --instance-ids ${{ secrets.EC2_INSTANCE_ID }} --region $AWS_REGION

      # --- Get EC2 public IP (prefer TF output; fallback to describe) ------
      - name: Get EC2 public IP
        id: ec2ip
        run: |
          if [ -n "${{ env.ec2_public_ip }}" ] && [ "${{ env.ec2_public_ip }}" != "null" ]; then
            echo "EC2_PUBLIC_IP=${{ env.ec2_public_ip }}" >> $GITHUB_ENV
          else
            ip=$(aws ec2 describe-instances --instance-ids ${{ secrets.EC2_INSTANCE_ID }} --region $AWS_REGION \
                 --query "Reservations[0].Instances[0].PublicIpAddress" --output text)
            echo "EC2_PUBLIC_IP=$ip" >> $GITHUB_ENV
          fi
          echo "Public IP is ${EC2_PUBLIC_IP}"

      # --- Sync data to S3 (fallback to secret if TF output not present) ---
      - name: Pick S3 bucket name
        run: |
          if [ -z "${{ env.s3_bucket_name }}" ] || [ "${{ env.s3_bucket_name }}" = "null" ]; then
            echo "s3_bucket_name=${{ secrets.S3_BUCKET_NAME }}" >> $GITHUB_ENV
          fi
      - name: Sync data folder to S3
        run: aws s3 sync ./data "s3://${{ env.s3_bucket_name }}/data"

      # --- Deploy on EC2: docker compose pull + up -------------------------
      # TIP: If you later enable SSM on the instance, switch from SSH to SSM RunCommand.
      - name: Deploy on EC2 via SSH
        uses: appleboy/ssh-action@v1
        with:
          host: ${{ env.EC2_PUBLIC_IP }}
          username: ubuntu
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            set -euxo pipefail
            cd /home/ubuntu/app || (mkdir -p /home/ubuntu/app && cd /home/ubuntu/app)
            aws s3 sync "s3://${{ env.s3_bucket_name }}/data" ./data || true
            aws ecr get-login-password --region ${{ env.AWS_REGION }} \
            | docker login --username AWS --password-stdin "${{ env.aws_account_id || secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"
            docker compose pull
            # Import CSVs into Mongo (matches your existing loop)
            for csv in ./data/*.csv; do
              [ -f "$csv" ] || continue
              collection=$(basename "$csv" .csv)
              echo "[INFO] Importing $csv into '$collection'..."
              docker exec citytaster-mongo mongoimport \
                --db "${{ env.DB_NAME }}" \
                --collection "$collection" \
                --type csv --headerline --file "/data/$collection.csv" --drop || true
            done
            docker compose up -d
            docker image prune -af || true

      # --- Output the URL --------------------------------------------------
      - name: Output Preview URL
        run: |
          echo "------------------------------------------"
          echo "Your app is live at: http://${EC2_PUBLIC_IP}"
          echo "------------------------------------------"

      # --- Optional: stop the instance after deploy ------------------------
      - name: Stop EC2 instance (optional)
        if: always()
        run: aws ec2 stop-instances --instance-ids ${{ secrets.EC2_INSTANCE_ID }} --region $AWS_REGION
